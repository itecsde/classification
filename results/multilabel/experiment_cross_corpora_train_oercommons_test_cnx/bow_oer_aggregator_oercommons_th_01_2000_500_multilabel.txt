---- EXPERIMENT DETAILS ----
CORPUS: oer_aggregator_oercommons
REPRESENTATION: BoW
THRESHOLD: 0.01
CLASSIFY METHOD: multilabel
METRIC: cosine
TFIDF: no
STEMMING: porter
SMOOTHING: 0.001
WEIGHTING: milne
ALGORITHM: SVC
#TRAIN: 2000
#TEST: 500

Getting train and test documents...
--- METHOD: get_documents_from_multilabel_database_bow_cross_corpora() ---
metadata: yes
freq: 3
Obtaining training documents from a part of the corpus bow_oer_aggregator_oercommons
Obtaining test documents from a part of the corpus bow_oer_aggregator_cnx
--- METHOD: get_unique_words_bow() ---
----- Multilabel Algorithm------
Creating Training Vectors...
Creating Training Feature Vectors...
Training multilabel classifier...
Classifying test documents (Prediction)
Metrics:
----------------
Hamming Loss:
0.107

Accuracy:
0.5

Precision:
0.740609395565

Recall:
0.55

Classification Report:
                            precision    recall  f1-score   support

                      Arts       0.68      0.45      0.55        33
                  Business       1.00      0.33      0.50        21
                Humanities       0.35      0.26      0.30        23
Mathematics and Statistics       0.76      0.49      0.60        65
    Science and Technology       0.78      0.66      0.71       293
           Social Sciences       0.65      0.34      0.44        65

               avg / total       0.74      0.55      0.62       500

F1-score
----------------
F1_SCORE (Macro): 0.516701158799
Precision: 0.740609395565
Recall: 0.55
---- Execution End ----
